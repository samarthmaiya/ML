{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "seperator = '#;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoreData = [scoreData.rstrip(\"\\n\") for scoreData in open(\"../TrainigDumpFile/finalscore.txt\", encoding='utf8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"../ModelDumpFile/sentenceScore.txt\",\"w\", encoding='utf8') \n",
    "positivearray = []\n",
    "negativearray = []\n",
    "globalarray = []\n",
    "matrixcolsize= ''\n",
    "label = []\n",
    "matrixcolsize = 20\n",
    "\n",
    "for row1 in scoreData:\n",
    "    _positiveScore = row1.split(seperator)[1]  \n",
    "    _negativeScore = row1.split(seperator)[2] \n",
    "    _positiveByGram = row1.split(seperator)[3]  \n",
    "    _negativeByGram1 = row1.split(seperator)[4] \n",
    "    trainingLable = row1.split(seperator)[5] \n",
    "    _positiveByGram = str(_positiveByGram)[1:-1]    \n",
    "    _negativeByGram = str(_negativeByGram1)[1:-1] \n",
    "    posdepricatingScore = 0\n",
    "    negdepricatingScore = 0\n",
    "    \n",
    "    _depricatingScore = row1.split(seperator)[8]\n",
    "    depricatingScore = ast.literal_eval(_depricatingScore)\n",
    "    \n",
    "    \n",
    "    if(len(depricatingScore) > 0):\n",
    "        posdepricatingScore = depricatingScore[0][0]\n",
    "    \n",
    "    if(len(depricatingScore) > 0):\n",
    "        negdepricatingScore = depricatingScore[0][1]\n",
    "    \n",
    "    positvebygramscorearray = []\n",
    "    label.append(trainingLable)    \n",
    "    \n",
    "    \n",
    "    if (len(_positiveByGram)>0):\n",
    "        positiveByGram = ast.literal_eval(str(_positiveByGram))        \n",
    "       \n",
    "        countarray = []        \n",
    "        for i in positiveByGram:\n",
    "            countarray.append(1.0 - posdepricatingScore)\n",
    "        a = np.append([0.8 - posdepricatingScore],countarray)\n",
    "        \n",
    "    if (len(_positiveByGram) == 0):\n",
    "        a =[] \n",
    "        \n",
    "    if (len(_negativeByGram)>0):\n",
    "        negativeByGram = ast.literal_eval(str(_negativeByGram))        \n",
    "       \n",
    "        negativecountarray = []        \n",
    "        for i in negativeByGram:\n",
    "            negativecountarray.append(-(1.0 - negdepricatingScore))\n",
    "        b = np.append([-(0.8 - negdepricatingScore)],negativecountarray)\n",
    "        \n",
    "    if (len(_negativeByGram) == 0):\n",
    "        b =[]  \n",
    "    c =np.append(a,b)    \n",
    " \n",
    "        \n",
    "    zeroappendablearray = []       \n",
    "    for j in range(matrixcolsize - len(c)):\n",
    "        zeroappendablearray.append(0)\n",
    "    ##print(zeroappendablearray)\n",
    "    d = np.append(c,zeroappendablearray)    \n",
    "    globalarray.append(d)     \n",
    "    f.writelines(_positiveScore)\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(_negativeScore)\n",
    "    f.writelines(str(seperator))\n",
    "    f.writelines(str(d))\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(round(float(_positiveScore)+float(_negativeScore)))) \n",
    "    f.writelines('\\n')\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = globalarray\n",
    "y = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7088, 7088)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96721346532536145"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96721346532536145, 0.96943034404963335, 0.96818416743224489, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96818416743224489"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96943034404963335"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96850023507287264"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testscoreData = [scoreData.rstrip(\"\\n\") for scoreData in open(\"../TestingDumpFile/testFinalScore.txt\", encoding='utf8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"../ModelDumpFile/predtictedTestData.txt\",\"w\", encoding='utf8') \n",
    "testpositivearray = []\n",
    "testnegativearray = []\n",
    "testtemparray = []\n",
    "globalarray = []\n",
    "matrixcolsize= ''\n",
    "label = []\n",
    "predictedArray = []\n",
    "count =0;\n",
    "for row in testscoreData:\n",
    "    _testpositiveScore = row.split(seperator)[1]  \n",
    "    _testnegativeScore = row.split(seperator)[2]\n",
    "    ##count = count +1;\n",
    "    ##print(_testnegativeScore,_testpositiveScore)\n",
    "    ##print(count)\n",
    "    testpositivearray.append(_testpositiveScore)\n",
    "    testnegativearray.append(_testnegativeScore)   \n",
    "    testtemparray.append(float(_testpositiveScore)- float(_testnegativeScore))\n",
    "matrixcolsize =round( max(testtemparray))\n",
    "matrixcolsize = 20\n",
    "\n",
    "\n",
    "    \n",
    "for row1 in testscoreData:   \n",
    "    \n",
    "    sentence = row1.split(seperator)[0]\n",
    "    _positiveScore = row1.split(seperator)[1]  \n",
    "    _negativeScore = row1.split(seperator)[2] \n",
    "    _positiveByGram = row1.split(seperator)[3]  \n",
    "    _negativeByGram1 = row1.split(seperator)[4]  \n",
    "    _positiveByGram = str(_positiveByGram)[1:-1]    \n",
    "    _negativeByGram = str(_negativeByGram1)[1:-1]   \n",
    "    positvebygramscorearray = []\n",
    "    label.append(round(float(_positiveScore)+float(_negativeScore))) \n",
    "    \n",
    "    _testingdepricatingScore = row1.split(seperator)[7]\n",
    "    testingdepricatingScore = ast.literal_eval(_testingdepricatingScore)\n",
    "    postestingdepricatingScore = 0\n",
    "    if(len(testingdepricatingScore) > 0):\n",
    "        ##postestingdepricatingScore = testingdepricatingScore[0][0]\n",
    "        postestingdepricatingScore = 0.5\n",
    "    negtestingdepricatingScore = 0\n",
    "    if(len(testingdepricatingScore) > 0):\n",
    "        ##negtestingdepricatingScore = testingdepricatingScore[0][1]\n",
    "        negtestingdepricatingScore = 0.5\n",
    "    \n",
    "    \n",
    "    if (len(_positiveByGram)>0):\n",
    "        positiveByGram = ast.literal_eval(str(_positiveByGram))        \n",
    "       \n",
    "        countarray = []        \n",
    "        for i in positiveByGram:\n",
    "            countarray.append(1.0 - postestingdepricatingScore)\n",
    "        a = np.append([(0.8 - postestingdepricatingScore)],countarray)\n",
    "        \n",
    "    if (len(_positiveByGram) == 0):\n",
    "        a =[] \n",
    "        \n",
    "    if (len(_negativeByGram)>0):\n",
    "        negativeByGram = ast.literal_eval(str(_negativeByGram))        \n",
    "       \n",
    "        negativecountarray = []        \n",
    "        for i in negativeByGram:\n",
    "            negativecountarray.append(-(1.0 - negtestingdepricatingScore))\n",
    "        b = np.append([-(0.8 - negtestingdepricatingScore)],negativecountarray)\n",
    "        \n",
    "    if (len(_negativeByGram) == 0):\n",
    "        b =[]  \n",
    "    c =np.append(a,b)    \n",
    " \n",
    "        \n",
    "    zeroappendablearray = []       \n",
    "    for j in range(matrixcolsize - len(c)):\n",
    "        zeroappendablearray.append(0)\n",
    "    ##print(zeroappendablearray)\n",
    "    d = np.append(c,zeroappendablearray)    \n",
    "    globalarray.append(d)\n",
    "    predictedArray.append(clf.predict(d.reshape(1, -1)))\n",
    "    \n",
    "    ##f.writelines(sentence)\n",
    "    ##f.writelines(';')\n",
    "    ##f.writelines(_positiveScore)\n",
    "    ##f.writelines(str(';')) \n",
    "    ##f.writelines(_negativeScore)\n",
    "    ##f.writelines(str(';'))\n",
    "    ##f.writelines(str(d))\n",
    "    ##f.writelines(str(';')) \n",
    "    f.writelines(str(clf.predict(d.reshape(1, -1))))\n",
    "    f.writelines('\\n')\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------done-----------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------done-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictedArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [line.rstrip(\"\\n\") for line in open(\"../TestingData/TestingData.txt\", encoding='utf8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testArray =[]\n",
    "for row in lines:    \n",
    "    a = np.array(row.split(\"\\t\")) \n",
    "    sentenceLabel = a[0] \n",
    "    testArray.append(sentenceLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90234209784294372"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(testArray,predictedArray,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87310835103775131"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(testArray, predictedArray, average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88177588996763756"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(testArray, predictedArray, average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.90234209784294372, 0.87310835103775131, 0.88177588996763756, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(testArray, predictedArray, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------END-----------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------END-----------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
