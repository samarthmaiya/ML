{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "from collections import Counter\n",
    "seperator = '#;'\n",
    "import operator\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countOccurance(sequence_of_sentences):\n",
    "    counts = Counter()\n",
    "    for word in sequence_of_sentences:\n",
    "        counts[word] += 1\n",
    "    return dict(counts)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileData = [fileData.rstrip(\"\\n\") for fileData in open(\"../TrainigDumpFile/wordtokanize.txt\", encoding='utf8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globalpositivearray = [];\n",
    "globalnegativearray = [];\n",
    "count = 0\n",
    "for row1 in fileData:        \n",
    "    positiveLexicon = row1.split(seperator)[1]\n",
    "    negativeLexicon = row1.split(seperator)[2]\n",
    "    positiveLexicon1 = yaml.load(positiveLexicon)\n",
    "    negativeLexicon1 = yaml.load(negativeLexicon)\n",
    "    \n",
    "    if (len(positiveLexicon1)> 0): \n",
    "        for indposlex in positiveLexicon1:\n",
    "            for k, v in indposlex.items():\n",
    "                while(v!=0):\n",
    "                    globalpositivearray.append(k)\n",
    "                    v=v-1 \n",
    "    if (len(negativeLexicon1)> 0): \n",
    "        for indneglex in negativeLexicon1:\n",
    "            for k, v in indneglex.items():\n",
    "                while(v!=0):\n",
    "                    globalnegativearray.append(k)\n",
    "                    v=v-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = countOccurance(globalpositivearray)\n",
    "x = countOccurance(globalnegativearray)\n",
    "_sorted_w = sorted(w.items(), key=operator.itemgetter(1))\n",
    "_sorted_x = sorted(x.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mxlength_w = _sorted_w[len(_sorted_w)-1][1]\n",
    "mxlength_x = _sorted_x[len(_sorted_x)-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_w =[]\n",
    "sorted_x =[]\n",
    "sorted_y =[]\n",
    "sorted_z =[]\n",
    "for indw  in _sorted_w:\n",
    "    mapw = (indw[0],(indw[1] -0.1)/(mxlength_w ))    \n",
    "    sorted_w.append(mapw)\n",
    "for indx  in _sorted_x:\n",
    "    mapx = (indx[0],(indx[1] -0.1)/(mxlength_x ))    \n",
    "    sorted_x.append(mapx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 202)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = len(sorted_w)-1\n",
    "x = len(sorted_x)-1\n",
    "w,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size 25375\n"
     ]
    }
   ],
   "source": [
    "print('Matrix Size',(w+1)*(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexiconCoboArray = []\n",
    "for i in sorted_w: \n",
    "    for j in sorted_x:       \n",
    "        _indArrayKey = []        \n",
    "        _indArrayVal = []\n",
    "        _indArrayKey.append(i[0])\n",
    "        _indArrayKey.append(j[0])\n",
    "        _indArrayVal.append(i[1])\n",
    "        _indArrayVal.append(j[1])\n",
    "        mapele = (_indArrayKey,_indArrayVal)\n",
    "        lexiconCoboArray.append(mapele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"../FrequencyCount/frequencyCount.txt\",\"w\", encoding='utf8') \n",
    "for row1 in lexiconCoboArray:    \n",
    "    bigram = row1[0]\n",
    "    score = row1[1]    \n",
    "    f.writelines(str(bigram))\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(score))    \n",
    "    f.writelines('\\n')\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexiconCoboArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexiconBygramreator(posArray,negArray):\n",
    "    finalBigramArray = []\n",
    "    for i in posArray:        \n",
    "        for j in negArray:\n",
    "            lexiconCoboArray = []\n",
    "            lexiconCoboArray.append(i)\n",
    "            lexiconCoboArray.append(j)\n",
    "            finalBigramArray.append(lexiconCoboArray)\n",
    "    return finalBigramArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkBigramOccourance(bigram):    \n",
    "    coutArray = []\n",
    "    for i in bigram:        \n",
    "        for j in lexiconCoboArray:\n",
    "            if(i == j[0]):\n",
    "                coutArray.append(j[1])\n",
    "    return coutArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigramValidation(bigramCount):    \n",
    "    posArray = []\n",
    "    negArray = []\n",
    "    count = 0\n",
    "    for bi in bigramCount:\n",
    "        posArray.append(bi[0])\n",
    "        negArray.append(bi[1])\n",
    "        count =count + 1\n",
    "    posArraySum = sum(posArray)\n",
    "    negArraySum = sum(negArray)   \n",
    "    return (posArraySum/count),(negArraySum/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoreData = [scoreData.rstrip(\"\\n\") for scoreData in open(\"../TrainigDumpFile/score.txt\", encoding='utf8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"../TrainigDumpFile/finalscore.txt\",\"w\", encoding='utf8') \n",
    "for row in scoreData:    \n",
    "    sentence = row.split(seperator)[0] \n",
    "    _positiveScore = row.split(seperator)[1]\n",
    "    _negativeScore = row.split(seperator)[2] \n",
    "    positiveByGram = row.split(seperator)[3]\n",
    "    negativeByGram = row.split(seperator)[4] \n",
    "    trainingLable = row.split(seperator)[5]    \n",
    "    _positiveLexiconWordCount = row.split(seperator)[6] \n",
    "    _negtiveLexiconWordCount = row.split(seperator)[7]    \n",
    "    positiveLexiconWordCount = yaml.load(_positiveLexiconWordCount)\n",
    "    negtiveLexiconWordCount = yaml.load(_negtiveLexiconWordCount)\n",
    "    normalisedArray = []\n",
    "    if((len(positiveLexiconWordCount)>0) and (len(negtiveLexiconWordCount)>0)):\n",
    "            posLexicalBigram = []\n",
    "            negLexicalBigram = []\n",
    "            for pi in positiveLexiconWordCount[0]:\n",
    "                posLexicalBigram.append(pi);\n",
    "            for ni in negtiveLexiconWordCount[0]:\n",
    "                negLexicalBigram.append(ni);            \n",
    "            bigram = lexiconBygramreator(posLexicalBigram,negLexicalBigram)            \n",
    "            bigramCount = checkBigramOccourance(bigram)\n",
    "            xx = bigramValidation(bigramCount) \n",
    "            normalisedArray.append(xx)            \n",
    "    f.writelines(sentence)\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(_positiveScore))\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(-ast.literal_eval(_negativeScore)))\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(positiveByGram))\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(negativeByGram))\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(trainingLable))    \n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(_positiveLexiconWordCount))\n",
    "    f.writelines(str(seperator)) \n",
    "    f.writelines(str(_negtiveLexiconWordCount))   \n",
    "    f.writelines(str(seperator))\n",
    "    f.writelines(str(normalisedArray))\n",
    "    f.writelines('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------done---------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------done---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
